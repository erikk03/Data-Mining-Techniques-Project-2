{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ΜΕΛΗ ΟΜΑΔΑΣ: \\\n",
    "ΚΑΓΙΑΤΣΚΑ ΕΡΙΚ - 1115202100043 \\\n",
    "ΚΑΛΑΜΠΟΚΗΣ ΕΥΑΓΓΕΛΟΣ - 1115202100045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows dropped: 0\n",
      "Train value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    165\n",
       "neutral     128\n",
       "negative     89\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test value counts:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    175\n",
       "negative     34\n",
       "neutral      31\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import from CSV sentiment data\n",
    "sentiment_df_2019 = pd.read_csv(\"data_sentiment/sentiment_2019.csv\", low_memory=False)\n",
    "sentiment_df_2023 = pd.read_csv(\"data_sentiment/sentiment_2023.csv\", low_memory=False)\n",
    "\n",
    "# Concatenate sentiment_df_2019 and sentiment_df_2023 in one dataframe\n",
    "df = pd.concat([sentiment_df_2019, sentiment_df_2023])\n",
    "\n",
    "# We want to drop lanes that are duplicate\n",
    "initial_row_count = df.shape[0]                                 # Initial row count\n",
    "df = df.drop_duplicates(subset=['id', 'review'], keep='first')  # Remove duplicates that are shown in both 2019 and 2023\n",
    "final_row_count = df.shape[0]                                   # Final row count\n",
    "rows_dropped = initial_row_count - final_row_count              # Rows dropped\n",
    "print(f\"Number of rows dropped: {rows_dropped}\")                # Print number of rows dropped\n",
    "\n",
    "# Split data: training (80%) and testing (20%)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Drop some data so we have good analogy between positive, negative and neutral sentiments\n",
    "positive_comments_train = train_df[train_df['sentiment'] == 'positive'].sample(n=400, random_state=42)\n",
    "train_df = train_df.drop(positive_comments_train.index)\n",
    "\n",
    "positive_comments_test = test_df[test_df['sentiment'] == 'positive'].sample(n=0, random_state=42)\n",
    "test_df = test_df.drop(positive_comments_test.index)\n",
    "\n",
    "# Print sentiments counts\n",
    "print(\"Train value counts:\")\n",
    "display(train_df['sentiment'].value_counts())\n",
    "print(\"Test value counts:\")\n",
    "display(test_df['sentiment'].value_counts())\n",
    "\n",
    "\n",
    "# Αποθήκευση σε αρχεία tsv\n",
    "train_df.to_csv('data_tsv/train.tsv', index=False)\n",
    "test_df.to_csv('data_tsv/test.tsv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Tf-idf Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(train_df['review'])\n",
    "tfidf_test = tfidf_vectorizer.transform(test_df['review'])\n",
    "\n",
    "# Save/store Tf-idf characteristics\n",
    "with open('data_pkl/tfidf_train.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_train, f)\n",
    "with open('data_pkl/tfidf_test.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_test, f)\n",
    "\n",
    "\n",
    "# Word2Vec\n",
    "tokenized_reviews = [review.split() for review in train_df['review']]\n",
    "word2vec_model = Word2Vec(tokenized_reviews, vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Extract embeddings from Word2Vec model\n",
    "def get_word2vec_embeddings(reviews, model):\n",
    "    embeddings = []                                                         # List to store the embeddings\n",
    "    for review in reviews:                                                  # Loop through each review in the reviews list\n",
    "        words = review.split()                                              # Split the review into words\n",
    "        word_vecs = [model.wv[word] for word in words if word in model.wv]  # Get each word's vector if it's in vocabulary of the model\n",
    "        if word_vecs:\n",
    "            embeddings.append(np.mean(word_vecs, axis=0))                   # Compute the mean of the word vectors\n",
    "        else:                                                               # If there are no word vectors\n",
    "            embeddings.append(np.zeros(model.vector_size))                  # Append a zero vector\n",
    "    return np.array(embeddings)                                             # Return list of embeddings\n",
    "\n",
    "\n",
    "word2vec_train = get_word2vec_embeddings(train_df['review'], word2vec_model)\n",
    "word2vec_test = get_word2vec_embeddings(test_df['review'], word2vec_model)\n",
    "\n",
    "# Save/store Word2Vec characteristics\n",
    "with open('data_pkl/word2vec_train.pkl', 'wb') as f:\n",
    "    pickle.dump(word2vec_train, f)\n",
    "with open('data_pkl/word2vec_test.pkl', 'wb') as f:\n",
    "    pickle.dump(word2vec_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in training data:\n",
      "sentiment\n",
      "positive    165\n",
      "neutral     128\n",
      "negative     89\n",
      "Name: count, dtype: int64\n",
      "Evaluating SVM with TFIDF features...\n",
      "Done.\n",
      "Evaluating SVM with Word2Vec features...\n",
      "Done.\n",
      "Evaluating Random Forest with TFIDF features...\n",
      "Done.\n",
      "Evaluating Random Forest with Word2Vec features...\n",
      "Done.\n",
      "Evaluating KNN with TFIDF features...\n",
      "Done.\n",
      "Evaluating KNN with Word2Vec features...\n",
      "Done.\n",
      "\n",
      "Results for SVM with TFIDF:\n",
      "Results Cross Validation: [0.74358974 0.79487179 0.78947368 0.73684211 0.76315789 0.86842105\n",
      " 0.65789474 0.65789474 0.76315789 0.78947368]\n",
      "Mean: 0.7564777327935224\n",
      "Final Results: 0.9208333333333333\n",
      "Class Counts in Predictions: {'negative': 26, 'neutral': 24, 'positive': 190}\n",
      "Classification Report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "    positive       1.00      0.76      0.87        34\n",
      "    negative       0.92      0.71      0.80        31\n",
      "     neutral       0.91      0.99      0.95       175\n",
      "\n",
      "    accuracy                           0.92       240\n",
      "   macro avg       0.94      0.82      0.87       240\n",
      "weighted avg       0.92      0.92      0.92       240\n",
      "\n",
      "\n",
      "Results for SVM with standardized Word2Vec:\n",
      "Results Cross Validation: [0.61538462 0.58974359 0.57894737 0.68421053 0.71052632 0.57894737\n",
      " 0.52631579 0.5        0.73684211 0.55263158]\n",
      "Mean: 0.6073549257759783\n",
      "Final Results: 0.7875\n",
      "Class Counts in Predictions: {'negative': 27, 'neutral': 32, 'positive': 181}\n",
      "Classification Report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.63      0.50      0.56        34\n",
      "    negative       0.44      0.45      0.44        31\n",
      "     neutral       0.87      0.90      0.89       175\n",
      "\n",
      "    accuracy                           0.79       240\n",
      "   macro avg       0.65      0.62      0.63       240\n",
      "weighted avg       0.78      0.79      0.78       240\n",
      "\n",
      "\n",
      "Results for Random Forest with TFIDF:\n",
      "Results Cross Validation: [0.76923077 0.87179487 0.84210526 0.76315789 0.78947368 0.89473684\n",
      " 0.71052632 0.68421053 0.81578947 0.86842105]\n",
      "Mean: 0.800944669365722\n",
      "Final Results: 0.8708333333333333\n",
      "Class Counts in Predictions: {'negative': 29, 'neutral': 37, 'positive': 174}\n",
      "Classification Report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.93      0.79      0.86        34\n",
      "    negative       0.59      0.71      0.65        31\n",
      "     neutral       0.92      0.91      0.92       175\n",
      "\n",
      "    accuracy                           0.87       240\n",
      "   macro avg       0.82      0.81      0.81       240\n",
      "weighted avg       0.88      0.87      0.87       240\n",
      "\n",
      "\n",
      "Results for Random Forest with standardized Word2Vec:\n",
      "Results Cross Validation: [0.71794872 0.66666667 0.78947368 0.68421053 0.81578947 0.84210526\n",
      " 0.63157895 0.55263158 0.76315789 0.81578947]\n",
      "Mean: 0.7279352226720649\n",
      "Final Results: 0.8916666666666667\n",
      "Class Counts in Predictions: {'negative': 30, 'neutral': 36, 'positive': 174}\n",
      "Classification Report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.90      0.79      0.84        34\n",
      "    negative       0.69      0.81      0.75        31\n",
      "     neutral       0.93      0.93      0.93       175\n",
      "\n",
      "    accuracy                           0.89       240\n",
      "   macro avg       0.84      0.84      0.84       240\n",
      "weighted avg       0.90      0.89      0.89       240\n",
      "\n",
      "\n",
      "Results for KNN with TFIDF:\n",
      "Results Cross Validation: [0.61538462 0.66666667 0.71052632 0.57894737 0.57894737 0.71052632\n",
      " 0.57894737 0.63157895 0.63157895 0.63157895]\n",
      "Mean: 0.633468286099865\n",
      "Final Results: 0.825\n",
      "Class Counts in Predictions: {'negative': 33, 'neutral': 35, 'positive': 172}\n",
      "Classification Report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.76      0.74      0.75        34\n",
      "    negative       0.51      0.58      0.55        31\n",
      "     neutral       0.90      0.89      0.89       175\n",
      "\n",
      "    accuracy                           0.82       240\n",
      "   macro avg       0.72      0.73      0.73       240\n",
      "weighted avg       0.83      0.82      0.83       240\n",
      "\n",
      "\n",
      "Results for KNN with standardized Word2Vec:\n",
      "Results Cross Validation: [0.61538462 0.48717949 0.55263158 0.52631579 0.60526316 0.52631579\n",
      " 0.36842105 0.5        0.52631579 0.47368421]\n",
      "Mean: 0.5181511470985155\n",
      "Final Results: 0.6625\n",
      "Class Counts in Predictions: {'negative': 39, 'neutral': 45, 'positive': 156}\n",
      "Classification Report\n",
      ":               precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.38      0.44      0.41        34\n",
      "    negative       0.29      0.42      0.34        31\n",
      "     neutral       0.84      0.75      0.79       175\n",
      "\n",
      "    accuracy                           0.66       240\n",
      "   macro avg       0.50      0.54      0.51       240\n",
      "weighted avg       0.70      0.66      0.68       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "target_names = ['positive', 'negative', 'neutral']\n",
    "\n",
    "# Load characteristics - Tf-idf\n",
    "with open('data_pkl/tfidf_train.pkl', 'rb') as f:\n",
    "    x_tfidf_train = pickle.load(f)\n",
    "with open('data_pkl/tfidf_test.pkl', 'rb') as f:\n",
    "    x_tfidf_test = pickle.load(f)\n",
    "\n",
    "# Load characteristics - Word Embeddings\n",
    "with open('data_pkl/word2vec_train.pkl', 'rb') as f:\n",
    "    x_word2vec_train = pickle.load(f)\n",
    "with open('data_pkl/word2vec_test.pkl', 'rb') as f:\n",
    "    x_word2vec_test = pickle.load(f)\n",
    "\n",
    "# Load labels\n",
    "train_df = pd.read_csv('data_tsv/train.tsv')\n",
    "test_df = pd.read_csv('data_tsv/test.tsv')\n",
    "\n",
    "y_train = train_df['sentiment'] # Column 'sentiment'\n",
    "y_test = test_df['sentiment']   # Column 'sentiment'\n",
    "\n",
    "# Print class distribution in training data\n",
    "print(\"Class distribution in training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Standardize the Word2Vec features\n",
    "scaler = StandardScaler()\n",
    "x_word2vec_train_scaled = scaler.fit_transform(x_word2vec_train)\n",
    "x_word2vec_test_scaled = scaler.transform(x_word2vec_test)\n",
    "\n",
    "# List od classifiers\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "     \"KNN\": KNeighborsClassifier(n_neighbors=15)\n",
    "}\n",
    "\n",
    "def evaluate_classifier(clf, x_train, y_train, x_test, y_test):\n",
    "    try:\n",
    "        # 10-fold Cross Validation\n",
    "        scores = cross_val_score(clf, x_train, y_train, cv=10)\n",
    "        clf.fit(x_train, y_train)\n",
    "        y_pred = clf.predict(x_test)\n",
    "\n",
    "        # Assuming y_test and y_pred are your true labels and predictions respectively\n",
    "        report = classification_report(y_test, y_pred, target_names=target_names, zero_division=0)\n",
    "\n",
    "        # Check class distribution in predictions\n",
    "        unique, counts = np.unique(y_pred, return_counts=True)\n",
    "        class_counts = dict(zip(unique, counts))\n",
    "\n",
    "        # Final score\n",
    "        test_score = clf.score(x_test, y_test)\n",
    "\n",
    "        # Return all values wanted and classification report\n",
    "        return {\n",
    "            'Results Cross Validation': scores,\n",
    "            'Mean': np.mean(scores),\n",
    "            'Final Results': test_score,\n",
    "            'Class Counts in Predictions': class_counts,\n",
    "            'Classification Report\\n': report\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during the evaluation of {clf.__class__.__name__}: {e}\")\n",
    "        return None\n",
    "\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    # Evaluate with tfidf\n",
    "    print(f\"Evaluating {name} with TFIDF features...\")\n",
    "    tfidf_results = evaluate_classifier(clf, x_tfidf_train, y_train, x_tfidf_test, y_test)\n",
    "    if tfidf_results:\n",
    "        results[f'{name} with TFIDF'] = tfidf_results\n",
    "    print(\"Done.\")\n",
    "\n",
    "    # Evaluate with w2v\n",
    "    print(f\"Evaluating {name} with Word2Vec features...\")\n",
    "    word2vec_results = evaluate_classifier(clf, x_word2vec_train_scaled, y_train, x_word2vec_test_scaled, y_test)\n",
    "    if word2vec_results:\n",
    "        results[f'{name} with standardized Word2Vec'] = word2vec_results\n",
    "    print(\"Done.\")\n",
    "\n",
    "# Print results\n",
    "for key, value in results.items():\n",
    "    print(f\"\\nResults for {key}:\")\n",
    "    for metric, score in value.items():\n",
    "        print(f\"{metric}: {score}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
